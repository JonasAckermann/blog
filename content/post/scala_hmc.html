---
title: "Scala HMC"
author: "Jonny Law"
date: "2019-04-30"
output: html_document
draft: true
---



<div id="scala-implementation" class="section level1">
<h1>Scala implementation</h1>
<p>To implement HMC, first identify the individual components of the algorithm and write them as referentially transparent functions. The first step is to sample the momentum, <span class="math inline">\(\phi\)</span> from the prior distribution, chosen to be a standard multivariate Normal distribution of dimension <span class="math inline">\(m\)</span>:</p>
<pre class="scala"><code>def priorPhi(m: Int) = 
  MultivariateGaussian(DenseVector.zeros[Double](m),
    DenseMatrix.eye[Double](m))</code></pre>
<p>The prior distribution of <span class="math inline">\(\phi\)</span> represented by the function <code>priorPhi</code> can be sampled from and the log-pdf can be calculated. The prior distribution can have a general covariance matrix <span class="math inline">\(\Sigma\)</span> to replace the <span class="math inline">\(m\)</span> dimensional identity matrix <span class="math inline">\(I_m\)</span>. Next the leapfrog discretization of Hamiltonâ€™s equations can be implemented:</p>
<pre class="scala"><code>def leapfrog(
  eps: Double,
  gradient: DenseVector[Double] =&gt; DenseVector[Double])(
  psi: DenseVector[Double],
  phi: DenseVector[Double]) = {
  val p1 = phi + eps * 0.5 * gradient(psi)
  val t1 = psi + eps * p1
  val p2 = p1 + eps * 0.5 * gradient(t1)
  (t1, p2)
}</code></pre>
<p>The parameters and momentum are represented as <code>DenseVector</code>s from the Breeze scientific computing library to simplify the implementation details, since addition and multiplication of vectors are already implemented. A function which performs multiple <code>leapfrog</code> steps dependent on the previous value can be implemented using <code>Vector.iterate</code>. Finally the HMC kernel can be written as a function from the parameters to a distribution over the new parameters, <code>DenseVector[Double] =&gt; Rand[DenseVector[Double]</code>:</p>
<pre class="scala"><code>def step(
  priorPhi: ContinuousDistr[Double],
  eps: Double,
  l: Int,
  gradient: DenseVector[Double] =&gt; DenseVector[Double],
  logPos: DenseVector[Double] =&gt; Double
  )(psi: DenseVector[Double]): Rand[DenseVector[Double]] = {
  for {
    phi &lt;- priorPhi
    (propPsi, propPhi) = leapfrogs(eps, gradient, l, psi, phi)
    a = logPos(propPsi) - priorPhi.logPdf(propPhi) -
      logPos(psi) + priorPhi.logPdf(phi)
    u &lt;- Uniform(0, 1)
    next = if (log(u) &lt; a) {
      propPsi
    } else {
      psi
    }
  } yield next
}</code></pre>
<p>The kernel can then be used to draw samples from a posterior distribution of a model with un-normalised log-posterior <code>logPos</code> and gradient, <code>grad</code> using <code>MarkovChain</code>:</p>
<pre class="scala"><code></code></pre>
</div>
