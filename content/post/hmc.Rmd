---
title: "Hamiltonian Monte Carlo in R"
author: "Jonny Law"
draft: TRUE
date: '2019-03-01'
slug: hmc
categories:
  - R
  - Bayesian
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(ggmcmc)
library(numDeriv)
library(zeallot)
library(coda)
library(parallel)

theme_set(theme_minimal())
```

# Bivariate Normal Model

The same bivariate Normal model from a [previous post implementing the Metropolis algorithm](metropolis_r.html) is used. See that post for details of deriving the log-likelihood and choice of prior distributions for the parameters.

```{r, echo=F}
bivariate_normal <- function(theta, n) {
  mu1 <- theta[1]
  sigma1 <- theta[2]
  mu2 <- theta[3]
  sigma2 <- theta[4]
  x <- rnorm(n / 2, mean = mu1, sd = sigma1)
  y <- rnorm(n / 2, mean = mu2, sd = sigma2)
  tibble(x, y)
}

theta = c(5.0, 0.5, 2.0, 1.5)
sims = bivariate_normal(theta, 1000)
xs <- as.matrix(sims)
qplot(sims$x, sims$y)
```

```{r, echo=F}
log_likelihood <- function(xs, theta) {
  apply(xs, 1, function(x) dnorm(x[1], mean = theta[1], sd = theta[2], log = T) + dnorm(x[2], mean = theta[3], sd = theta[4], log = T)) %>% sum()
}
log_prior <- function(theta) {
  dnorm(theta[1], sd = 3, log = T) + dnorm(theta[3], sd = 3, log = T) + dgamma(theta[2], shape = 3.0, rate = 3.0, log = T) + dgamma(theta[4], shape = 3.0, rate = 3.0, log = T)
}
log_posterior <- function(xs) function(theta) log_likelihood(xs, theta) + log_prior(theta)
```

# Hamiltonian Monte Carlo

Metropolis-Hastings requires the specification of a proposal distribution, the log-likelihood and prior distributions for the parameters. The proposal distribution is often a multivariate Normal distribution with mean corresponding to the previous value of the parameters, the covariance of the proposal distribution is a tuning parameter. This proposal results in random walk behaviour and although the MH algorithm is guaranteed to converge it can take a long time to get satisfactory draws from the posterior distribution.

The gradient of the un normalised log-posterior distribution can be used to explore the posterior distribution more efficiently. Hamiltonian Monte Carlo (HMC) is an MCMC method which utilises a discretisation of Hamilton's equations in order to model a physical system where the parameters are represented by the position of a particle in $\theta \in \mathbb{R^d}$. In order to implement HMC, the posterior distribution is augmented with a momentum vector, $\phi$, which is used to propose updates to the position which can be far away from the initial position.

```{r}
leapfrog_step <- function(gradient, step_size, position, momentum) {
  momentum1 <- momentum + gradient(position) * 0.5 * step_size
  position1 <- position + step_size * momentum1
  momentum2 <- momentum + gradient(position1) * 0.5 * step_size

  list(position = position1, momentum = momentum2)
}
```

```{r}
leapfrogs <- function(gradient, step_size, l) {
  function(position, momentum) {
    for (i in 1:l) {
      c(position, momentum) %<-% leapfrog_step(gradient, step_size, position, momentum)
    }
    list(position = position, momentum = momentum)
  }
}
```

```{r}
log_acceptance <- function(propPosition, propMomentum, position,
                           momentum, log_posterior) {
  log_posterior(propPosition) + sum(dnorm(propMomentum, log = T)) - log_posterior(position) - sum(dnorm(momentum, log = T))
}
```

```{r}
hmc_step <- function(log_posterior, gradient, step_size, l, position) {
  d <- length(position)
  momentum <- rnorm(d)
  c(propPosition, propMomentum) %<-% leapfrogs(gradient, step_size, l)(position, momentum)
  a <- log_acceptance(propPosition, propMomentum, position, momentum, log_posterior)
  if (log(runif(1)) < a) {
    propPosition
  } else {
    position
  }
}
```

```{r}
hmc <- function(log_posterior, gradient, step_size, l, initP, m) {
  out <- matrix(NA_real_, nrow = m, ncol = length(initP))
  out[1, ] <- initP
  for (i in 2:m) {
    out[i, ] <- hmc_step(log_posterior, gradient, step_size, l, out[i-1,])
  }
  out
}
```

From the previous post, the log-posterior distribution is the sum of the log-prior and the log-likelihood. The log-likelihood is given by:

$$\log p(y|\mu, \Sigma) = \sum_{j=1}^2\left(-\frac{N}{2}\log(2\pi\sigma_{j}^2) - \frac{1}{2\sigma_{j}^2}\sum_{i=1}^N(y_{ij}-\mu_j)^2\right)$$
Where $\Sigma = \operatorname{diag}(\sigma_1, \sigma_2)$, the prior distributions are chosen to be:

$$\begin{align}
p(\mu_j) &= \mathcal{N}(0, 3), \\
p(\sigma_j) &= \textrm{Gamma}(3, 3), \quad j = 1, 2.
\end{align}$$

The log-pdf of these distributions are:

$$\begin{align}
\log p(\mu_j) &= -\frac{1}{2}\log(18\pi)-\frac{\mu_j^2}{18} \\
\log p(\sigma_j) &= \alpha\log(\beta)-\log(\Gamma(\alpha)) + (\alpha-1)\log(\sigma_j)-\beta \sigma_j
\end{align}$$

The gradient of the log-posterior with respect to each of the paramters can be written as:

$$
\begin{align}
\frac{\partial \ell}{\partial \mu_j} &= \frac{1}{\sigma_j^2}\sum_{i=1}^N(y_{ij}-\mu_j) - \frac{\mu_j}{9}, \\
\frac{\partial \ell}{\partial \sigma_j} &= -\frac{N}{\sigma_j} +  \frac{1}{\sigma_j^3}\sum_{i=1}^N(y_{ij}-\mu_j)^2 + \frac{2}{\sigma_j}-3, \quad j = 1, 2.
\end{align}
$$

In R the gradient can be programmed by hand:

```{r}
gradient <- function(ys) {
  function(theta) {
    mu <- c(theta[1], theta[3])
    sigma <- c(theta[2], theta[4])
    n <- nrow(ys)
    c(1/sigma[1]^2*sum(ys[,1] - mu[1]) - mu[1]/9,
      -n/sigma[1] + sum((ys[,1] - mu[1])^2) / sigma[1]^3 + 2/sigma[1] - 3,
      1/sigma[2]^2*sum(ys[,2] - mu[2]) - mu[2]/9,
      -n/sigma[2] + sum((ys[,2] - mu[2])^2) / sigma[2]^3 + 2/sigma[2] - 3)
  }
}
```

To ensure the value of the gradient is correct we can compare it to a numerical approximation of the gradient using the [https://cran.r-project.org/web/packages/numDeriv/numDeriv.pdf](numDeriv) package:

```{r}
approx_gradient <- function(xs) {
  function(theta) {
    grad(log_posterior(xs), theta)
  }
}

compare_gradient <- function(theta, tol) {
  abs(gradient(xs)(theta) - approx_gradient(xs)(theta)) < tol
}

compare_gradient(theta, 1e-3)
```

It appears the calculated derivative is correct. Next, HMC works best when the leapgrog proposal can propose unconstrained values of the parameters which lie on the whole real line. A `transform` function is defined for the parameters, $\theta$ which calculates the exponential of the standard deviation parameters. The log-posterior is calculated using the transformed values, the appropriate transformation and inverse transformation functions can be written as:

```{r}
transform <- function(theta) {
  c(theta[1], exp(theta[2]), theta[3], exp(theta[4]))
}

inv_transform <- function(theta) {
  c(theta[1], log(theta[2]), theta[3], log(theta[4]))
}
```

The leapfrog step proposal is calculated using the unconstrained parameters, hence the derivative of the log-jacobian of the transformation is required to be added to the value of the gradient of the log-density. Then the derivative of the log-jacobian is calculated to get the value of the gradient corresponding to the unconstrained parameters in the leapfrog step.

```{r}
log_jacobian <- function(theta) {
  c(0, theta[2], 0, theta[4])
}

deriv_log_jacobian <- function(theta) {
  c(0, 1, 0, 1)
}
```

The derivative of the log-jacobian contributes the value 1 to each of the partial derivatives $\frac{\partial \ell}{\partial \sigma_j}, j = 1, 2.$

```{r}
# evaluate the log-posterior on the appropriate scale, using the transform function
bounded_log_posterior <- function(xs) {
  function(theta) {
    log_posterior(xs)(transform(theta)) + sum(log_jacobian(theta))
  }
}

bounded_gradient <- function(xs) {
  function(theta) {
    gradient(xs)(theta) + deriv_log_jacobian(theta)
  }
}

out_hmc <- hmc(log_posterior(xs), gradient(xs), 
               0.01, 4, theta, 10000)
```

```{r}
actual_values = tibble(
  Parameter = c("mu1", "sigma1", "mu2", "sigma2"),
  actual_value = c(5.0, 0.5, 2.0, 1.5)
)

# Transform parameters to bounded and put in a tibble
out_hmc <- as_tibble(t(apply(out_hmc, 1, transform)))
colnames(out_hmc) <- actual_values$Parameter

out_hmc %>%
  mutate(iteration = row_number()) %>%
  gather(key = Parameter, value, -iteration) %>%
  inner_join(actual_values) %>%
  ggplot(aes(x = iteration, y = value)) + 
  geom_line() +
  geom_hline(aes(yintercept = actual_value), linetype = "dashed") +
  facet_wrap(~Parameter, scales = "free_y")
```

In order to compare efficiency for similar Markov chain Monte Carlo (or other simulation) algorithms the amount of information from each sample can be measured. This is termed the effective sample size, corresponding to the number of effective independent draws from the posterior distribution. The code below calculates the ESS of each parameter in the chain.

```{r}
coda::effectiveSize(mcmc(out_hmc))
```

To measure the efficiency, the ESS per second can be measured. 

# Rcpp implementation

Again, this code can be written using Rcpp. 

```{Rcpp, eval=FALSE}
#include <Rcpp.h>
using namespace Rcpp;
// [[Rcpp::plugins(cpp11)]]

// [[Rcpp::export]]
double logDensity(NumericMatrix ys, NumericVector p) {
  double ll = 0;
  int n = ys.nrow();
  for (int i = 0; i < n; i++) {
    ll += R::dnorm(ys(i, 0), p(0), p(1), true) + R::dnorm(ys(i, 1), p(2), p(3), true);
  }
  return ll;
}

// [[Rcpp::export]]
NumericVector gradientCpp(NumericMatrix ys, NumericVector position) {
  int n = ys.nrow();
  NumericVector ssy1 = (ys(_,0) - position(0)) * (ys(_,0) - position(0));
  NumericVector ssy2 = (ys(_,1) - position(2)) * (ys(_,1) - position(2));
  NumericVector out = NumericVector::create(
    1/position(1) * sum(ys(_,0) - position(0) ) - position(0) / 9,
    -n/position(1) + std::accumulate(ssy1.begin(), ssy1.end(), 0.0) / pow(position(1), 3) + 2/position(2) - 3,
    1/position(3) *sum(ys(_,1) - position(2) ) - position(2) / 9,
    -n/position(3) + std::accumulate(ssy2.begin(), ssy2.end(), 0.0) / pow(position(3), 3)) + 2/position(2) - 3;
  
  return out;
}

// [[Rcpp::export]]
NumericVector leapfrogCpp(
    Function gradient,
    NumericMatrix ys,
    NumericVector qp,
    double stepSize) {
  
  // unasign values
  int d = qp.size() / 2;
  NumericVector momentum(d);
  NumericVector position(d);
  for (int i = 0; i < d; i++) {
    momentum(i) = qp(d + i);
    position(i) = qp(i);
  }
  
  NumericVector momentum1 = momentum + as<NumericVector>(gradient(ys, position)) * 0.5 * stepSize;
  NumericVector position1 = position + stepSize * momentum1;
  NumericVector momentum2 = momentum + as<NumericVector>(gradient(ys, position1)) * 0.5 * stepSize;
  
  NumericVector newqp(2 * d);
  for (int i = 0; i < d; i++) {
    newqp(i) = position1(i);
    newqp(d + i) = momentum2(i);
  }
  return newqp;
}
```

```{r}

```


```{r, eval=FALSE}
leapfrogs <- function(gradient, step_size, l) {
  function(position, momentum) {
    for (i in 1:l) {
      c(position, momentum) %<-% leapfrogCpp(gradient, step_size, position, momentum)
    }
    list(position = position, momentum = momentum)
  }
}

out_hmc <- hmc(function(theta) logDensity(xs, theta), function(theta) gradientCpp(xs, theta), 0.01, 4, theta, 1000)
```


```{Rcpp, eval=FALSE}
// [[Rcpp::export]]
double logAcceptance(NumericMatrix ys,
                     NumericVector prop, 
                     NumericVector qp) {
  int d = qp.size() / 2;
  double phiP = 0.0;
  double propPhiP = 0.0;
  for (int i = 0; i < d; i++) {
    phiP += R::dnorm(qp(d + i), 0.0, 1.0, true);
    propPhiP += R::dnorm(prop(d + i), 0.0, 1.0, true);
  }
  
  NumericVector propPosition(d);
  NumericVector position(d);
  for (int i = 0; i < d; i++) {
    propPosition(i) = prop(i);
    position(i) = qp(i);
  }
  
  double a = logDensity(ys, transform(propPosition)) - phiP - logDensity(ys, transform(position)) + propPhiP;
  return a;
}

// [[Rcpp::export]]
NumericVector leapfrogs(
    NumericMatrix ys,
    NumericVector qp,
    double stepSize,
    int l) {
  
  // initialise vectors
  int d = qp.size();
  NumericVector prop(d);
  for (int i = 0; i < d; i++) {
    prop(i) = qp(i);
  }
  
  // perform l leapfrogs
  for (int i = 0; i < l; i++) {
    prop = leapfrog(ys, prop, stepSize);
  }
  
  return prop;
}

// [[Rcpp::export]]
NumericVector initialMomentum(int d) {
  NumericVector momentum(d);
  for (int j = 0; j < d; j++) {
    momentum(j) = R::rnorm(0.0, 1.0);
  }
  return momentum;
}

// [[Rcpp::export]]
NumericVector hmcStep(NumericMatrix ys,
                      NumericVector position,
                      double stepSize,
                      int l) {
  int d = position.size();
  NumericVector momentum = initialMomentum(d);
  NumericVector qp(2 * d);
  for (int i = 0; i < d; i++) {
    qp(i) = position(i);
    qp(d + i) = momentum(i);
  }
  NumericVector prop = leapfrogs(ys, qp, stepSize, l);
  double a = logAcceptance(ys, prop, qp);
  double u = R::runif(0, 1);
  NumericVector nextParameter(d);
  if (log(u) < a) {
    for (int i = 0; i < d; i++) {
      nextParameter(i) = qp(i);
    }
  } else {
    nextParameter = position;
  }
  
  return nextParameter;
}

// [[Rcpp::export]]
NumericMatrix hmc(
    NumericMatrix ys,
    NumericVector position,
    double stepSize,
    int l,
    int N) {
  int d = position.size();
  NumericMatrix mat(N, d);
  
  // initialise first row of output
  for (int j = 0; j < d; j++) {
    mat(0, j) = position(j);
  }
  
  // create markov chain
  for (int i = 1; i < N; i++) {
    NumericVector newP = hmcStep(ys, mat(i-1, _), stepSize, l);
    for (int j = 0; j < d; j++) {
      mat(i, j) = newP(j);
    }
  }
  return mat;
}
```

